{
    "pages": [
        {
            "text": "\nIn order to have better understanding of public encryption methods, I spend some time understanding math problems behind them. Most of these problems provides a Trapdoor functionality.\nTrapdoor is a function that is easy to do it in one way and really hard to do it the otherway. in other words having A we can easily compute B. But by having B is really hard to get back to A. This hardness can be due to the cost or time needed.\n\n```\nA --> B\nA <x- B\n```\nIf we have two number $A$ and $B$ and $ C = A  B $, break C back to A and B is called integer factorization. Prime factorization is a subset of the problem with an extra constraint that factors should be prime. \ne.g.\n$$ 864  =  2  2  2  2  2  3  3  3 $$\n\nThis become interesting and hard problem if : \n\n- $A$ and $B$ are prime numbers\n- $A$ and $B$ are very large (about two thousand bits long) \n- $A$ and $B$ are randomly chosen\n\nthen $C$ is called semiprime.\n\nSome of the methods built on top of this problem are : \n- RSA (Rivest\u2013Shamir\u2013Adleman)\n- Paillier\n- Benaloh\n- Blum\u2013Goldwasser\n- Cayley\u2013Purser\n- Damg\u00e5rd\u2013Jurik\n- GMR\n- Goldwasser\u2013Micali\n- Rabin\n- Okamoto\u2013Uchiyama\n- Schmidt\u2013Samoa\n\nHardness:\n\n for 1024-bit RSA, it is estimated by having 100 Machines, it will take more than 2000 years to break it.\n \nRSA simple implementation \nThis code is just for learning, please do not use it for any production code.\naddopted from here\nBrute-force primality test\nRSA settings\n-  a^b mod (prime number) p = r\n       when prime number the solution is equally likely to be any number between zero and prime number\n\n       reverse is hard (to detect b having a, p, r )\n\n       if we use a large prime number (e.g. hundreds of digits)\n           - all human computation power, thousends of years\n\n           [time needed to find it]\n\n\n\n\n    e.g.\n    Cramer\u2013Shoup\n    DH\n    DSA\n    ECDH\n    ECDSA\n    EdDSA\n    EKE\n    ElGamal\n    MQV\n    Schnorr\n    SPEKE\n    SRP\n    STS\n- ECC requires smaller key size  (256bits vs 3072bits for RSA)  (recommended : 384)\n\n    - draw eleptic curve in python\n\n        max is like mirror (key size)\n        private key = \"n\" (number of times running the method)  ??\n\n        starting point A\n        ending point Z\n\n\n\t\timport numpy as np\n\t\timport matplotlib.pyplot as plt\n\n\t\tdef main():\n\t\t    a = -1\n\t\t    b = 1\n\n\t\t    y, x = np.ogrid[-5:5:100j, -5:5:100j]\n\t\t    plt.contour(x.ravel(), y.ravel(), pow(y, 2) - pow(x, 3) - x  a - b, [0])\n\t\t    plt.grid()\n\t\t    plt.show()\n\n\t\tif name == 'main':\n\t\t    main()\n\n\n the elliptic-curve discrete logarithm problem  (ECC is here)\n\n\n\n\tp Field that the Curve is defined over\n\ta,b = Values define the Curve\n\tG = the generator point\n\tn = prime order of G\n\th = cofactor\nPost-quantum cryptography \nhttps://en.wikipedia.org/wiki/Post-quantumcryptography\n\nPQCrypto conference series since 2006\n Shor's algorithm",
            "tags": "",
            "url": "public_key_encryption_math_problems.html",
            "id": "public_key_encryption_math_problems",
            "title": "Public Key Encryption Math Problems"
        },
        {
            "text": "\nHere is a list of linear algrebra functions provided by pytorch. The order of the concepts in this notebook is based on deep learning book (by Goodfellow et. al) chapter 2.\nA tensor is an array of numbers, that may have, \n- zero dimensions, and be a scalar , \n- one dimension, and be a vector \n- two dimensions, and be a matrix \n- or more dimensions.\nimporting torch\nScalars\nA scalar is a number (Integers, real numbers, rational numbers) usually denoted by italic font\nVectors\nA vector is a 1-D array of numbers\n$$ \\textbf{x} = \\left[\n            \\begin{array}{c}\n              x1 \\\\\n              x2 \\\\\n              x3 \\\\\n              ... \\\\\n              xn \\\\\n            \\end{array}\n        \\right] $$\nDistance between two vectors\nReturns the p-norm of (input - other)\nMatrix \nA matrix is a 2-D array of numbers(Integers, real numbers, rational numbers) usually denoted by captial letters\n$$ \\textbf{A} = \\left[\n            \\begin{array}{c}\n              x{11} & x{12} & x{13} & ... & x{1n} \\\\\n              x{21} & x{22} & x{23} & ... & x{2n} \\\\\n              x{31} & x{32} & x{33} & ... & x{3n} \\\\\n              ... & ... & ... & ... & ...\\\\\n              x{m1} & x{m2} & x{m3} & ... & x{mn} \\\\\n            \\end{array}\n        \\right] $$\nIdentity Matrix\nA 2-D tensor with ones on the diagonal and zeros elsewhere\nMatrix Addition\n$$ E = A + B $$\nMatrix (Dot) Product\nIf matrix A is a n x m Tensor, matrix B is a m x p Tensor, out will be a n x p Tensor.\n\n$$ C = AB $$\n$$ C{i,j} = \\sum{k} A{i,k}B{k,j} $$\nMatrix-vector Product\nPerforms a matrix-vector product of the matrix mat and the vector vec.\n\n$$ C = vA $$\n$$ C{i,j} = \\sum{k} A{i,k}v{k} $$\nSlicing\nTrace\n$$ Tr(A) = \\sum{i} A{i,i} $$\nMatrix Transpose\n$$ (A^T){i,j} = A{j,i}$$\nMatrix Inversion\nSpecial Matrices\nSymmetric Matrix\n$$ A = A^T $$\nOrthogonal matrix\n$$ A^T A = A A^T = I $$\n$$ A^{-1} = A^{T} $$\nSystems of Equations\n$$ Ax = b $$\nX, LU = torch.gesv(B, A) returns the solution to the system of linear equations represented by AX=BAX=B\nLU contains L and U factors for LU factorization of A.\nNorm \nFunctions that measure how \u201clarge\u201d a vector is, similar to a distance between zero and the point represented by the vector\n$$ L^{p} - Norm $$\nEigendecomposition\nComputing the eigenvalues and eigenvectors of a real square matrix.\nSingular Value Decomposition\n$$ A = UDV^{T} $$",
            "tags": "",
            "url": "pytorch_linear_algebra.html",
            "id": "pytorch_linear_algebra",
            "title": "Linear Algebra using Torch"
        }
    ]
}